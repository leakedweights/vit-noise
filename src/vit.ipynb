{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4Sv6CvSXnqS"
      },
      "source": [
        "# Vision Transformer for Noise Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYJRPnxTXrcW"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install jax flax optax matplotlib tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t294gJvsSwJ2"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "from flax.training import train_state\n",
        "\n",
        "import optax\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from typing import Any, Optional\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7RX15_bW-tl"
      },
      "source": [
        "## Vision Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDnjqW-UXfAB"
      },
      "outputs": [],
      "source": [
        "class MLPBlock(nn.Module):\n",
        "  hidden_size: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "\n",
        "    output_shape =  x.shape[-1]\n",
        "\n",
        "    x = nn.Dense(features=self.hidden_size)(x)\n",
        "    x = nn.gelu(x)\n",
        "    x = nn.Dense(features=output_shape)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "  n_heads: int\n",
        "  input_size: int\n",
        "  mlp_size: int\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    y = nn.LayerNorm(name='input_norm')(x)\n",
        "    y = nn.MultiHeadDotProductAttention(num_heads=self.n_heads)(x)\n",
        "    x = x + y\n",
        "    norm_output = nn.LayerNorm(name='attention_norm')(x)\n",
        "    y = MLPBlock(hidden_size=self.mlp_size)(x)\n",
        "    return x + y\n",
        "\n",
        "class VisionTransformer(nn.Module):\n",
        "    n_layers: int\n",
        "    n_heads: int\n",
        "    n_classes: int\n",
        "    mlp_size: int\n",
        "    patch_size: int\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, image):\n",
        "        patch_size = self.patch_size\n",
        "\n",
        "        H, W, C = image.shape[1], image.shape[2], image.shape[3]\n",
        "        n_patches = (H // patch_size) * (W // patch_size)\n",
        "\n",
        "        image = image.reshape(image.shape[0], H // patch_size, patch_size, W // patch_size, patch_size, C)\n",
        "        image = image.transpose(0, 1, 3, 2, 4, 5)\n",
        "        image = image.reshape(image.shape[0], n_patches, -1)\n",
        "\n",
        "        embedding = nn.Dense(image.shape[-1])(image)\n",
        "\n",
        "        pe = self.param('pos_embedding', nn.initializers.normal(), (1, n_patches, image.shape[-1]))\n",
        "        x = embedding + pe\n",
        "\n",
        "        for _ in range(self.n_layers):\n",
        "            x = EncoderBlock(input_size=image.shape[-1],\n",
        "                             n_heads=self.n_heads,\n",
        "                             mlp_size=self.mlp_size)(x)\n",
        "\n",
        "        x = nn.LayerNorm()(x)\n",
        "        x = x.mean(axis=1)\n",
        "        x = nn.Dense(self.n_classes)(x)\n",
        "\n",
        "        return jax.nn.softmax(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NzQ5edyXx0c"
      },
      "source": [
        "## Noise datasets\n",
        "\n",
        "For the details of generating Perlin noise see https://en.wikipedia.org/wiki/Perlin_noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdjpFPpodAqW",
        "outputId": "a5f7c898-7667-41d9-c632-389e484d956f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-100-ef2dbdf63ac2>:3: DeprecationWarning: jax.random.shuffle is deprecated. Use jax.random.permutation with independent=True.\n",
            "  jax.random.shuffle(shuffle_key, indices)\n"
          ]
        }
      ],
      "source": [
        "def create_jax_dataset(shuffle_key, samples, labels, batch_size):\n",
        "    indices = jnp.arange(samples.shape[0])\n",
        "    jax.random.shuffle(shuffle_key, indices)\n",
        "    samples, labels = samples[indices], labels[indices]\n",
        "\n",
        "    for i in range(0, len(samples), batch_size):\n",
        "        yield {\n",
        "            'image': samples[i:i + batch_size],\n",
        "            'label': labels[i:i + batch_size]\n",
        "        }\n",
        "\n",
        "batch_size = 32\n",
        "dataset = list(create_jax_dataset(shuffle_key, all_samples, all_labels, batch_size))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0FYzjN6cnvM"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkCfQBVVb1GZ"
      },
      "outputs": [],
      "source": [
        "class TrainState(train_state.TrainState):\n",
        "  batch_stats: Any\n",
        "\n",
        "def train_step(state: train_state.TrainState, batch):\n",
        "  def loss_fn(params):\n",
        "    logits, updates = state.apply_fn(\n",
        "      {'params': params, 'batch_stats': state.batch_stats},\n",
        "      x=batch['image'], train=True, mutable=['batch_stats'])\n",
        "    loss = optax.softmax_cross_entropy_with_integer_labels(\n",
        "      logits=logits, labels=batch['label'])\n",
        "    return loss, (logits, updates)\n",
        "\n",
        "  grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
        "  (loss, (logits, updates)), grads = grad_fn(state.params)\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  state = state.replace(batch_stats=updates['batch_stats'])\n",
        "  metrics = {\n",
        "    'loss': loss,\n",
        "    'accuracy': jnp.mean(jnp.argmax(logits, -1) == batch['label']),\n",
        "  }\n",
        "  return state, metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "bI54uSAEIBCs",
        "outputId": "0f415373-988f-4986-c2c0-8438fa0befed"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-111-5aa7cb99d702>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mopt_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
          ]
        }
      ],
      "source": [
        "n_epochs = 5\n",
        "init_image = jnp.ones(image_shape)\n",
        "\n",
        "model = VisionTransformer(n_layers=12, n_heads=8, mlp_size=2048, n_classes=3, patch_size=16)\n",
        "\n",
        "optimizer = optax.adam(learning_rate=0.001)\n",
        "params, batch_stats = model.init(init_key, init_image)\n",
        "opt_state = optimizer.init(variables)\n",
        "\n",
        "state = TrainState(\n",
        "    step=train_step,\n",
        "    apply_fn=model.apply,\n",
        "    params=params,\n",
        "    tx=optimizer,\n",
        "    batch_stats=batch_stats,\n",
        "    opt_state=opt_state\n",
        ")\n",
        "\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "    epoch_losses = []\n",
        "    epoch_accuracies = []\n",
        "    for batch in dataset:\n",
        "      state, metrics = train_step(state, batch)\n",
        "      epoch_losses.append(metrics['loss'])\n",
        "      epoch_accuracies.append(metrics['accuracy'])\n",
        "\n",
        "    avg_loss = np.mean(epoch_losses)\n",
        "    avg_accuracy = np.mean(epoch_accuracies)\n",
        "    losses.append(avg_loss)\n",
        "    accuracies.append(avg_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}, Loss: {avg_loss}, Accuracy: {avg_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivEgSVkQdXRF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
